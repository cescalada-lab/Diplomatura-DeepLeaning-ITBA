{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importamos Librerias"
      ],
      "metadata": {
        "id": "A35mHsocSatT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-mpXuyJT9UO"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import gensim\n",
        "import os, re, csv, math, codecs\n",
        "num_words=30000\n",
        "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=num_words+2,)\n",
        "data = np.concatenate((training_data, testing_data), axis=0)\n",
        "targets = np.concatenate((training_targets, testing_targets), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEiPTqOBT_V7",
        "outputId": "91c5d6de-d1fb-4285-f6ce-0e8123c0aac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories: [0 1]\n",
            "Number of unique words: 30000\n"
          ]
        }
      ],
      "source": [
        "num_words=len(np.unique(np.hstack(data)))\n",
        "print(\"Categories:\", np.unique(targets))\n",
        "print(\"Number of unique words:\", num_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargamos Drive"
      ],
      "metadata": {
        "id": "158Q31kTSiQY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSFu-CU_r2QK"
      },
      "source": [
        "Agregar este archivo a la carpeta de google drive\n",
        "\n",
        "https://drive.google.com/open?id=1zgSN39uX3OWxGyqwGDypKxQRokE0_njG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9mmn9fpUIY6",
        "outputId": "494e14c5-3e4e-4c61-a9d0-942ea31acfae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparamos los Embeddings"
      ],
      "metadata": {
        "id": "xoQ24FXSStDc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tOvUY-MUJGH",
        "outputId": "fddc2a23-9400-4614-f49f-3a7fd892257e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Review length: 234.75892\n",
            "Standard Deviation: 173\n"
          ]
        }
      ],
      "source": [
        "length = [len(i) for i in data]\n",
        "print(\"Average Review length:\", np.mean(length))\n",
        "print(\"Standard Deviation:\", round(np.std(length)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHY8EhzvUdzt",
        "outputId": "4d0bd0a7-6b94-476d-95b8-7db64e92d13f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 1\n",
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ]
        }
      ],
      "source": [
        "print(\"Label:\", targets[0])\n",
        "\n",
        "Label: 1\n",
        "print(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lY7mGCLUf0M",
        "outputId": "adf07cf7-51d7-4be4-e4e7-9d938fd57124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal measures the hair is big lots of boobs bounce men wear those cut tee shirts that show off their stomachs sickening that men actually wore them and the music is just # trash that plays over and over again in almost every scene there is trashy music boobs and paramedics taking away bodies and the gym still doesn't close for # all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n"
          ]
        }
      ],
      "source": [
        "index = imdb.get_word_index()\n",
        "reverse_index = dict([(value, key) for (key, value) in index.items()]) \n",
        "decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[1]] )\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yp9nq3GuKL8",
        "outputId": "cf930e6d-8c1b-4744-c374-a41cb498b411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word embeddings...\n",
            "found 999995 word vectors\n"
          ]
        }
      ],
      "source": [
        "#load embeddings\n",
        "EMBEDDING_DIR = \"/content/drive/My Drive/DeepLearning/Laboratorios/NLP/\"\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open(EMBEDDING_DIR+'wiki-news-300d-1M.vec', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDEVfp7RY489"
      },
      "outputs": [],
      "source": [
        "embeddings_index[\"car\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlY6kxXlUv_b"
      },
      "outputs": [],
      "source": [
        "embed_dim=300\n",
        "embedding_matrix=np.zeros([num_words+4,embed_dim])\n",
        "for word, idx in index.items():\n",
        "  if idx <= num_words and word in embeddings_index:\n",
        "    embedding_matrix[idx+3,:]=embeddings_index[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HdJ8KrrZszC"
      },
      "outputs": [],
      "source": [
        "maxlen=1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r9jiL4QarNw"
      },
      "outputs": [],
      "source": [
        "data = pad_sequences(data,maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiL4twmwas3F",
        "outputId": "52ef0583-f7f4-4973-d9bc-842764f5ca9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoPdGTyaaudk",
        "outputId": "c4053368-2e7e-4c7d-d9ff-4f05f23556be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(data[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9HdnsE2awBy"
      },
      "outputs": [],
      "source": [
        "data=np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri0xt9ueaxlK",
        "outputId": "3bef961a-6d83-4864-9209-6bcd64a8339b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Armamos el Modelo"
      ],
      "metadata": {
        "id": "X0p7SqzYTEZu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjoQz25NazxB",
        "outputId": "6b2ae70f-923e-4acf-d7c8-b81601274968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1000, 300)         9001200   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 1000, 64)          134464    \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 500, 64)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 500, 128)          57472     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,197,297\n",
            "Trainable params: 196,097\n",
            "Non-trainable params: 9,001,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import optimizers\n",
        "nb_words=num_words+4\n",
        "num_filters=64\n",
        "model = Sequential()\n",
        "model.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(num_filters*2, 7, activation='relu', padding='same'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  #multi-label (k-hot encoding)\n",
        "\n",
        "adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamos el Modelo"
      ],
      "metadata": {
        "id": "iYNo2lJSTNIj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnkm8psrbO3A",
        "outputId": "ba9a6d3d-19b9-4a97-aadd-2458d17c86cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1250/1250 [==============================] - 520s 415ms/step - loss: 0.3906 - accuracy: 0.8155 - val_loss: 0.2834 - val_accuracy: 0.8822\n",
            "Epoch 2/5\n",
            "1250/1250 [==============================] - 501s 401ms/step - loss: 0.2773 - accuracy: 0.8854 - val_loss: 0.3234 - val_accuracy: 0.8548\n",
            "Epoch 3/5\n",
            "1250/1250 [==============================] - 496s 397ms/step - loss: 0.2366 - accuracy: 0.9050 - val_loss: 0.2484 - val_accuracy: 0.8980\n",
            "Epoch 4/5\n",
            "1250/1250 [==============================] - 496s 397ms/step - loss: 0.2006 - accuracy: 0.9210 - val_loss: 0.2491 - val_accuracy: 0.8952\n",
            "Epoch 5/5\n",
            "1250/1250 [==============================] - 500s 400ms/step - loss: 0.1704 - accuracy: 0.9337 - val_loss: 0.3321 - val_accuracy: 0.8727\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f876a164210>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model.fit(data,targets,batch_size=32,epochs=5,validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WymZVTH8b4lQ",
        "outputId": "d4b65ded-cd72-4dfb-96ac-7c09e51105bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
              "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
              "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
              "       ...,\n",
              "       [-0.1016, -0.0326, -0.0645, ...,  0.1472,  0.0353,  0.0965],\n",
              "       [-0.0605, -0.0081,  0.1003, ...,  0.126 , -0.0304, -0.0316],\n",
              "       [-0.2191, -0.0352, -0.0829, ..., -0.1367, -0.2115, -0.0451]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "embedding_matrix"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "4 Fasttext - Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}