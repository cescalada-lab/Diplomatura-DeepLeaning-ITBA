{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorio2 TNG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uooxp8Ntn5Xp"
      },
      "source": [
        "# Laboratorio 2: TNG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxwkKR4QLNCg"
      },
      "source": [
        "## Analizamos el dataset Twenty News Groups, aplicando Naive Bayes de la librería SkLearn y respondiendo el siguiente cuestionario de referencia:\n",
        "\n",
        "1- ¿Cuántos artículos tiene el train set de TNG?\n",
        "\n",
        "2- ¿A qué categoría pertenece el artículo cuyo índice es [5]?\n",
        "\n",
        "3- Indique cuál de las siguientes palabras se encuentra dentro de la lista de stopwords utilizadas.\n",
        "\n",
        "4- Escriba en minúsculas qué da como resultado la lemmatización de la palabra 'being'.\n",
        "\n",
        "5- Escriba en minúsculas qué da como resultado el stemming de la palabra 'president'.\n",
        "\n",
        "6- ¿Cuál es el tamaño del vocabulario si luego de procesar los artículos según la notebook se descartan las palabras que aparecen en más del 60% de los artículos y aparecen por lo menos 10 veces?\n",
        "\n",
        "7- ¿A qué índice corresponde el stemming de la palabra 'president' dentro del vocabulario?\n",
        "\n",
        "8- ¿Cuál es el accuracy para el train set del modelo de Naive Bayes Multinomial entrenado con alpha=3?\n",
        "\n",
        "9- ¿Cuál es la cantidad de artículos en el test set del dataset de Twenty News Group?\n",
        "\n",
        "10-¿Cuál es el accuracy para el test set del modelo de Naive Bayes Multinomial entrenado anteriormente?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N86NcpIdnm4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a94df2-118f-4851-ad82-f0781fdbb412"
      },
      "source": [
        "#Descargamos el dataset TNG para analizarlo\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=False)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3EgSKKl3jSH"
      },
      "source": [
        "# Respuesta1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J31jZ_BD3dUh",
        "outputId": "87eb4f83-41f4-46a7-8c14-27ed99aa512c"
      },
      "source": [
        "len(twenty_train.data) #Cantidad de artículos periodísticos"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGPs-n0q3cza"
      },
      "source": [
        "# Respuesta2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iApCa0v3tnx",
        "outputId": "49c60f85-b77f-4338-ba74-0e28061264e3"
      },
      "source": [
        "twenty_train[\"target\"][5] #Lista que indica a que clase pertenece los artículos\n",
        "twenty_train[\"target_names\"][4] #Descripción de las clases\n",
        "\n",
        "print(twenty_train[\"target_names\"][twenty_train[\"target\"][5]]) #Categoría que pertenece al artículo cuyo índice es [5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comp.sys.mac.hardware\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao9x_TMo4PCq"
      },
      "source": [
        "\n",
        "\n",
        "Vamos a aplicar el siguiente procesamiento utilizando los conceptos vistos en clase:\n",
        "\n",
        "    Tokenization (nltk)\n",
        "    Lemmatization (nltk)\n",
        "    Stop Words (nltk)\n",
        "    Stemming (nltk)\n",
        "    Filtrado de palabras\n",
        "    Obtención del vocabulario (countvectorizer)\n",
        "    Transformación de los artículos en vectores\n",
        "    Armado del modelo de Naive Bayes Multinomial\n",
        "    Evaluación con el Train Set\n",
        "    Evaluación con el Test Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuEMba3s4a1h",
        "outputId": "f1235157-5993-44d2-dc9e-e2dc0b1124b9"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCYTgwU_4oFe",
        "outputId": "e8d19edc-74f3-4fe3-9830-863d970c448f"
      },
      "source": [
        "#Procesamos todos los artículos:\n",
        "articulos_procesados=list()\n",
        "for idx in range(len(twenty_train.data)):\n",
        "    if idx%1000==0:\n",
        "        print(f'se procesaron {idx} artículos')\n",
        "    art=twenty_train.data[idx]\n",
        "    tok=word_tokenize(art)\n",
        "    lem=[lemmatizer.lemmatize(x,pos='v') for x in tok]\n",
        "    stop = [x for x in lem if x not in stopwords.words('english')]\n",
        "    stem=[stemmer.stem(x) for x in stop]\n",
        "    alpha=[x for x in stem if x.isalpha()]\n",
        "    articulos_procesados.append(\" \".join(alpha))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "se procesaron 0 artículos\n",
            "se procesaron 1000 artículos\n",
            "se procesaron 2000 artículos\n",
            "se procesaron 3000 artículos\n",
            "se procesaron 4000 artículos\n",
            "se procesaron 5000 artículos\n",
            "se procesaron 6000 artículos\n",
            "se procesaron 7000 artículos\n",
            "se procesaron 8000 artículos\n",
            "se procesaron 9000 artículos\n",
            "se procesaron 10000 artículos\n",
            "se procesaron 11000 artículos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_ditPmy4y_V"
      },
      "source": [
        "# Respuesta3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziOvXTNj4qvs",
        "outputId": "c7452bca-2e66-4779-a4c1-edd009b09d1c"
      },
      "source": [
        "#Buscamos cual de estas 3 palabras se encuentran dentro de stopwords:\n",
        "print(\"themselves\" in stopwords.words('english'))\n",
        "print(\"always\" in stopwords.words('english'))\n",
        "print(\"anything\" in stopwords.words('english'))\n",
        "#La palabra \"themselves\" se encuentra dentro de la lista de stopwords utilizadas"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbF9lqYj45oT"
      },
      "source": [
        "# Respuesta4:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zsDoHPA64-y_",
        "outputId": "850854bc-4dc9-4bbc-8b23-0f8256c2cc4a"
      },
      "source": [
        "lemmatizer.lemmatize('being',pos='v')  # Lemmatizamos la palabra \"being\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'be'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z94Pml0P5E9g"
      },
      "source": [
        "# Respuesta5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6aimZMxm5H_g",
        "outputId": "311c856e-2619-498a-968a-b9b94eed1234"
      },
      "source": [
        "stemmer.stem('president')  #Buscamos el stemming de la palabra 'president'."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'presid'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7wKz_Zk52aA"
      },
      "source": [
        "Vamos a continuar cargando codigo para seguir con las respuestas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LokhKsC549m",
        "outputId": "40402d8f-14f9-426e-c63b-b23e5aa533d5"
      },
      "source": [
        "# Importamos CountVectorizer para procesar las palabras:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer(max_df=0.6,min_df=10) #  Paso los parametros \n",
        "count_vect.fit(articulos_procesados) #Aprende el vocabulario y le asigna un código a cada palabra"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=0.6, max_features=None, min_df=10,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BQRDwVu658Y"
      },
      "source": [
        "# Respuesta6:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiwWGose7AwW",
        "outputId": "0aaab1b9-ce37-4084-f877-45c838c1b97a"
      },
      "source": [
        "len(count_vect.vocabulary_)   #Tamaño del vocabulario"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py0AmRE59RAF"
      },
      "source": [
        "# Respuesta 7:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVWGGnBY7ClT",
        "outputId": "db421a5c-d8f5-42b8-db16-b9f7c364bfbd"
      },
      "source": [
        "count_vect.vocabulary_['presid']  #Índice del stemming de la palabra 'president' dentro del vocabulario"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddj3fSYvbb2z"
      },
      "source": [
        "# Respuesta 8:\n",
        "### Evaluación con el Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4f2gEwfb0bQ"
      },
      "source": [
        "X_train_data= count_vect.transform(articulos_procesados)  #Se arma el vector de frecuencias de palabras por articulo"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULP63XZzbd3t",
        "outputId": "e551ede6-148d-49cb-ab27-f15f3595803e"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB            #Implementamos un clasificador Naive Bayes discreto\n",
        "clf = MultinomialNB(alpha=3.0)                           #Instanciamos la clase y utilizamos smoothing laplaciano con alpha=3.\n",
        "clf.fit(X_train_data.toarray(), twenty_train[\"target\"])  #Entrenamos nuestro modelo"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=3.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OLj8xV1cYhh",
        "outputId": "923b6754-aa94-4a69-9ac6-1832120cd1bd"
      },
      "source": [
        "#Calculamos el Accuracy de train\n",
        "Accuracy_Train_Set=clf.score(X_train_data.toarray(), twenty_train[\"target\"])\n",
        "print(Accuracy_Train_Set)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9129397207000177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhPRSB93d_qX"
      },
      "source": [
        "# Respuesta 9:\n",
        "### Evaluación con el Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwNShJwqeBcF"
      },
      "source": [
        "#Descargamos el dataset TNG para test\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAz18ogRhhBQ",
        "outputId": "942e96e3-3539-4a4b-92b3-63cd4a0c54b9"
      },
      "source": [
        "len(twenty_test.data)  #cantidad de artículos en el test set"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ztf0qM0GhjRj"
      },
      "source": [
        "# Respuesta 10:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWtFYSNrhlqh",
        "outputId": "bafc8598-256c-49bd-fd81-15fffa0dcb27"
      },
      "source": [
        "#Procesamos todos los artículos para test:\n",
        "articulos_procesados_test=list()\n",
        "for idx in range(len(twenty_test.data)):\n",
        "    if idx%1000==0:\n",
        "        print(f'se procesaron {idx} artículos')\n",
        "    art=twenty_test.data[idx]\n",
        "    tok=word_tokenize(art)\n",
        "    lem=[lemmatizer.lemmatize(x,pos='v') for x in tok]\n",
        "    stop = [x for x in lem if x not in stopwords.words('english')]\n",
        "    stem=[stemmer.stem(x) for x in stop]\n",
        "    alpha=[x for x in stem if x.isalpha()]\n",
        "    articulos_procesados_test.append(\" \".join(alpha))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "se procesaron 0 artículos\n",
            "se procesaron 1000 artículos\n",
            "se procesaron 2000 artículos\n",
            "se procesaron 3000 artículos\n",
            "se procesaron 4000 artículos\n",
            "se procesaron 5000 artículos\n",
            "se procesaron 6000 artículos\n",
            "se procesaron 7000 artículos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_DhPaHYytGn"
      },
      "source": [
        "#Transformamos los artículos de test procesados\n",
        "X_test_data= count_vect.transform(articulos_procesados_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ctTF-twyyRn",
        "outputId": "3a740df5-875c-4de1-e804-c1b451f7680d"
      },
      "source": [
        "#Calculamos el score de test con el modelo entrenado para train\n",
        "clf.score(X_test_data.toarray(), twenty_test[\"target\"]) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7841210833775889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}